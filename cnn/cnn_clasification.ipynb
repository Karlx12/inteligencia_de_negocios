{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d15a33d",
   "metadata": {},
   "source": [
    "# Clasificación de Tumores Cerebrales con CNN (Entrenamiento y Validación 80/20)\n",
    "\n",
    "Este notebook está preparado para el desarrollo y entrenamiento de una CNN sobre imágenes MRI. Incluye:\n",
    "- Separación automática 80/20 para entrenamiento y validación\n",
    "- Visualización de datos\n",
    "- Definición y entrenamiento del modelo\n",
    "- Guardado automático de checkpoints cada N épocas\n",
    "- Tamaño de imagen: 512x512 píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d61936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configuración de semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Comprobar si hay GPU disponible\n",
    "print(\"Dispositivos disponibles:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f\"  {device.name}\")\n",
    "print(f\"¿GPU disponible? {'GPU' in [d.device_type for d in tf.config.list_physical_devices()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de rutas\n",
    "BASE_DIR = Path(os.path.join(os.getcwd(), '../total/archive/Training'))\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Detectar clases automáticamente\n",
    "classes = [d.name for d in BASE_DIR.iterdir() if d.is_dir()]\n",
    "print(f\"Clases detectadas: {classes}\")\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Parámetros\n",
    "IMG_SIZE = 512  # Tamaño de imagen actualizado a 512x512\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "CHECKPOINT_EVERY = 5  # Guardar cada N épocas\n",
    "MODEL_DIR = Path(os.path.join(os.getcwd(), '../models'))\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e800aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generador de datos con separación 80/20 (entrenamiento/validación)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 80% train, 20% val\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    str(BASE_DIR),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),  # Actualizado a 512x512\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    str(BASE_DIR),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),  # Actualizado a 512x512\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = {v: k for k, v in class_indices.items()}\n",
    "print(\"Mapeo de clases:\", class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495641be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algunas imágenes de entrenamiento\n",
    "plt.figure(figsize=(15, 8))\n",
    "images, labels = next(train_generator)\n",
    "labels = np.argmax(labels, axis=1)\n",
    "for i in range(min(10, len(images))):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(f\"Clase: {class_names[labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir arquitectura de la CNN\n",
    "def create_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks: EarlyStopping, ReduceLROnPlateau, y ModelCheckpoint cada N épocas\n",
    "checkpoint_path = str(MODEL_DIR / 'cnn_checkpoint_epoch_{epoch:02d}.h5')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    period=CHECKPOINT_EVERY,  # Guardar cada N épocas\n",
    "    verbose=1\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "callbacks = [model_checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo con validación\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo final\n",
    "final_model_path = MODEL_DIR / 'brain_tumor_cnn_model_final.h5'\n",
    "model.save(str(final_model_path))\n",
    "print(f\"Modelo final guardado en: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la curva de pérdida y precisión\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Precisión del modelo')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Entrenamiento', 'Validación'], loc='lower right')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Pérdida del modelo')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380dcdd",
   "metadata": {},
   "source": [
    "**Notas:**\n",
    "- El entrenamiento se realiza con separación 80/20 para entrenamiento y validación.\n",
    "- Se guardan checkpoints automáticos cada N épocas y el modelo final al terminar.\n",
    "- Puedes ajustar los hiperparámetros y arquitectura según tus necesidades."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
